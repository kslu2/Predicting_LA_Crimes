{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng8Id0_nYrdA"
      },
      "source": [
        "# Feature Importance\n",
        "This python file will be to perform Feature Importance using Shapley values to determine the ranking of features in terms of how much they influence the model in effectively predicting the crime codes. The file will start with preprocessing the data similar to previous learning files then performing feature importance with Shapley values\n",
        "\n",
        "\n",
        "**Authors:** Kevin Lu, Shrusti Jain, Smeet Patel, Taobo Liao\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIzSxXnoLlLO"
      },
      "source": [
        "# Imports and Graph Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vWRR1GNOJUnp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "#%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9TtAWe0_JWPk"
      },
      "outputs": [],
      "source": [
        "#for some reason, this needs to be in a separate cell\n",
        "params={\n",
        "    \"font.size\":15,\n",
        "    \"lines.linewidth\":5,\n",
        "}\n",
        "plt.rcParams.update(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90N4am7rJXpI",
        "outputId": "3bb773b0-849c-45b4-849d-7961a2a7f2c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GOlOSBBJdWWdh8z2oS19aEROm-3oTB4d\n",
            "To: c:\\Users\\jain9\\Predicting_LA_Crimes\\src\\basic_nn_model.pkl\n",
            "\n",
            "  0%|          | 0.00/658k [00:00<?, ?B/s]\n",
            " 80%|███████▉  | 524k/658k [00:00<00:00, 4.62MB/s]\n",
            "100%|██████████| 658k/658k [00:00<00:00, 5.31MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_tvxGoEQEMFialDlTOjGmLaU8xz7_Yom\n",
            "To: c:\\Users\\jain9\\Predicting_LA_Crimes\\src\\basic_nn_model_time_sensitive.pkl\n",
            "\n",
            "  0%|          | 0.00/659k [00:00<?, ?B/s]\n",
            "100%|██████████| 659k/659k [00:00<00:00, 6.51MB/s]\n",
            "100%|██████████| 659k/659k [00:00<00:00, 6.51MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1enYGeEeWNFDr-qHQuCNnb4q6yV7O9cpg\n",
            "To: c:\\Users\\jain9\\Predicting_LA_Crimes\\src\\basic_nn_model_part12.pkl\n",
            "\n",
            "  0%|          | 0.00/637k [00:00<?, ?B/s]\n",
            " 82%|████████▏ | 524k/637k [00:00<00:00, 5.10MB/s]\n",
            "100%|██████████| 637k/637k [00:00<00:00, 5.64MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yafkDVoUJd6L2scEZeu1Rdg4de8XqfXo\n",
            "To: c:\\Users\\jain9\\Predicting_LA_Crimes\\src\\ft_import_batch.npy\n",
            "\n",
            "  0%|          | 0.00/4.87M [00:00<?, ?B/s]\n",
            " 22%|██▏       | 1.05M/4.87M [00:00<00:00, 8.44MB/s]\n",
            " 75%|███████▌  | 3.67M/4.87M [00:00<00:00, 15.2MB/s]\n",
            "100%|██████████| 4.87M/4.87M [00:00<00:00, 15.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LGqGZvJ5c86IVeC6mS8P1tEyxT_BDsBg\n",
            "To: c:\\Users\\jain9\\Predicting_LA_Crimes\\src\\feature_names.pkl\n",
            "\n",
            "  0%|          | 0.00/4.92k [00:00<?, ?B/s]\n",
            "100%|██████████| 4.92k/4.92k [00:00<?, ?B/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!gdown 1GOlOSBBJdWWdh8z2oS19aEROm-3oTB4d\n",
        "!gdown 1_tvxGoEQEMFialDlTOjGmLaU8xz7_Yom\n",
        "!gdown 1enYGeEeWNFDr-qHQuCNnb4q6yV7O9cpg\n",
        "!gdown 1yafkDVoUJd6L2scEZeu1Rdg4de8XqfXo\n",
        "!gdown 1LGqGZvJ5c86IVeC6mS8P1tEyxT_BDsBg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0cV0982DwPbA"
      },
      "outputs": [],
      "source": [
        "# Basic Neural Network with 3 hidden layers, BatchNorm and dropout\n",
        "class BasicNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate):\n",
        "        super(BasicNN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            # Input layer\n",
        "            nn.Linear(input_size, hidden_sizes[0]),\n",
        "            nn.BatchNorm1d(hidden_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Hidden Layer 1\n",
        "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "            nn.BatchNorm1d(hidden_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "\n",
        "            # Hidden Layer 2\n",
        "            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
        "            nn.BatchNorm1d(hidden_sizes[2]),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Hidden Layer 3 (New layer added)\n",
        "            nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
        "            nn.BatchNorm1d(hidden_sizes[3]),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Output layer\n",
        "            nn.Linear(hidden_sizes[3], output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47u4qdNrJZrX",
        "outputId": "7f576d2f-f227-42f0-eb4d-aec08c287dcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BasicNN(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=297, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=256, out_features=180, bias=True)\n",
              "    (4): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.2, inplace=False)\n",
              "    (7): Linear(in_features=180, out_features=120, bias=True)\n",
              "    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=120, out_features=80, bias=True)\n",
              "    (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): Linear(in_features=80, out_features=69, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataframe objects from the Deep Learning notebook\n",
        "# crime_df_train = pd.read_pickle('/content/train.pkl')\n",
        "# crime_df_debug = pd.read_pickle('/content/debug.pkl')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "input_size = 297\n",
        "hidden_sizes = [256, 180, 120, 80]\n",
        "output_size = 69\n",
        "learning_rate = 1e-3\n",
        "dropout_rate = 0.2\n",
        "milestones = [10, 15]\n",
        "\n",
        "model = BasicNN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size, dropout_rate=dropout_rate)\n",
        "\n",
        "# Load pre-trained weights into the model\n",
        "model.load_state_dict(torch.load('basic_nn_model.pkl', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1tPEswGrmaI"
      },
      "source": [
        "# Loading Preprocessed Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aEXXDJtrpXz"
      },
      "source": [
        "Rather than performing preprocessing each time to extract a single batch of data, we save a randomly selected batch as a .npy file and the feature names as a .pkl file, so as to save on both time and memory and allow results to be reproducible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1KrQmMumsE_c"
      },
      "outputs": [],
      "source": [
        "batch_data = np.load(\"ft_import_batch.npy\")\n",
        "with open(\"feature_names.pkl\", 'rb') as labelsfile:\n",
        "    ungrouped_feature_names = pickle.load(labelsfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFNyyPVIz-qP"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2XMmEfB0GDM",
        "outputId": "3dcb9abb-4cdd-4d8e-80b5-cfae23d3a549"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PermutationExplainer explainer:  17%|█▋        | 709/4096 [01:53<09:10,  6.15it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model_predict, batch_data)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compute SHAP values for the batch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\explainers\\_permutation.py:77\u001b[0m, in \u001b[0;36mPermutationExplainer.__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, main_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m              outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\explainers\\_explainer.py:266\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args))]\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[1;32m--> 266\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    271\u001b[0m     output_indices\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\explainers\\_permutation.py:133\u001b[0m, in \u001b[0;36mPermutationExplainer.explain_row\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[0;32m    130\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# evaluate the masked model\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     row_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(fm),) \u001b[38;5;241m+\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\utils\\_masked_model.py:60\u001b[0m, in \u001b[0;36mMaskedModel.__call__\u001b[1;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(masks\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupports_delta_masking\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delta_masking_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# we need to convert from delta masking to a full masking call because we were given a delta masking\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# input but the masker does not support delta masking\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m         full_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_masker_cols), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\utils\\_masked_model.py:206\u001b[0m, in \u001b[0;36mMaskedModel._delta_masking_call\u001b[1;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[0;32m    203\u001b[0m     batch_positions[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_positions[i] \u001b[38;5;241m+\u001b[39m num_varying_rows[i]\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# joined_masked_inputs = self._stack_inputs(all_masked_inputs)\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubset_masked_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m _assert_output_input_match(subset_masked_inputs, outputs)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearize_link \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink \u001b[38;5;241m!=\u001b[39m links\u001b[38;5;241m.\u001b[39midentity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linearizing_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\models\\_model.py:21\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m---> 21\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     is_tensor \u001b[38;5;241m=\u001b[39m safe_isinstance(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m is_tensor \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(out)\n",
            "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mmodel_predict\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(X_tensor)\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def model_predict(X):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_tensor)\n",
        "        return torch.softmax(outputs, dim=1).cpu().numpy()  # Return probabilities\n",
        "\n",
        "explainer = shap.Explainer(model_predict, batch_data)\n",
        "\n",
        "# Compute SHAP values for the batch\n",
        "shap_values = explainer(batch_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1yp6yJo_4yn",
        "outputId": "7603c57c-a2a7-4001-efec-33a989d355b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<module 'shap' from '/usr/local/lib/python3.10/dist-packages/shap/__init__.py'>\n"
          ]
        }
      ],
      "source": [
        "print(shap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2lv_85K2nZP"
      },
      "outputs": [],
      "source": [
        "average_shap_values = np.mean(shap_values.values, axis=0)  # Shape: (297, 69)\n",
        "for target_class in range(69):\n",
        "    class_shap_values = average_shap_values[:, target_class]  # Shape: (297,)\n",
        "\n",
        "    sorted_indices = np.argsort(-np.abs(class_shap_values))  # Sort by absolute importance\n",
        "    sorted_shap_values = class_shap_values[sorted_indices]\n",
        "    sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n",
        "\n",
        "    # Plot the averaged SHAP values for this class\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(sorted_feature_names[:20], sorted_shap_values[:20])  # Top 20 features\n",
        "    plt.xlabel(\"Average SHAP Value\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.title(f\"Averaged Feature Importance for Class {target_class}\")\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"averaged_summary_plot_class_{target_class}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwjILz10CZrb"
      },
      "source": [
        "Actual feature descriptions:\n",
        "* Feature 1: Date Occured\n",
        "* Feature 2: Vict Age Was 0 (Unlisted)\n",
        "* Feature 3: Vict Age\n",
        "* Feature 4: Rpt Dist No\n",
        "* Feature 5: Area\n",
        "* Feature 6: Time Occurred\n",
        "* Feature 7: Premise Code\n",
        "* Features 8-13: Status\n",
        "* Features 14-92: Weapon Used Cd\n",
        "* Features 93-112: Vict Descent\n",
        "* Features 113-117: Vict Sex\n",
        "* Features 118-297: Mocodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sWOJcAS6Qwc",
        "outputId": "d2a0cdff-5cea-4172-b23b-94688e7fe1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Features Across All Classes:\n",
            "Feature: Premise Code, Mean Absolute SHAP Value: 0.0069\n",
            "Feature: Mocode_0344, Mean Absolute SHAP Value: 0.0064\n",
            "Feature: Vict Age, Mean Absolute SHAP Value: 0.0056\n",
            "Feature: Mocode_0329, Mean Absolute SHAP Value: 0.0033\n",
            "Feature: Weapon Used Cd_211.0, Mean Absolute SHAP Value: 0.0028\n",
            "Feature: Date Occ, Mean Absolute SHAP Value: 0.0025\n",
            "Feature: Mocode_NaN, Mean Absolute SHAP Value: 0.0017\n",
            "Feature: Mocode_0416, Mean Absolute SHAP Value: 0.0016\n",
            "Feature: Time Occurred, Mean Absolute SHAP Value: 0.0012\n",
            "Feature: Mocode_0325, Mean Absolute SHAP Value: 0.0012\n"
          ]
        }
      ],
      "source": [
        "mean_abs_shap_values = np.mean(np.abs(shap_values.values), axis=(0, 2))  # Shape: (297,)\n",
        "# Sort features by their mean absolute SHAP value\n",
        "sorted_indices = np.argsort(-mean_abs_shap_values)\n",
        "sorted_shap_values = mean_abs_shap_values[sorted_indices]\n",
        "sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n",
        "\n",
        "most_important_feature = sorted_feature_names[0]\n",
        "most_important_value = sorted_shap_values[0]\n",
        "\n",
        "print(\"\\nTop 10 Features Across All Classes:\")\n",
        "for feature, importance in zip(sorted_feature_names[:10], sorted_shap_values[:10]):\n",
        "    print(f\"Feature: {feature}, Mean Absolute SHAP Value: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRY03qDnV8zI"
      },
      "source": [
        "From this trial, we can see that most of the important features are Mocodes. This makes sense because mocodes provides a detailed description of the environment of the crime scene before it happens. Such as \"Stranger\" or \"Domestic Violence\" etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCRlC5AzFZMq",
        "outputId": "922b1afd-58a5-4c4f-9dab-ed220d235efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SHAP Values of Each Feature Ranked\n",
            "Feature: Mocodes, Summed Mean Absolute SHAP Value: 0.0328\n",
            "Feature: Premise Code, Summed Mean Absolute SHAP Value: 0.0069\n",
            "Feature: Vict Age, Summed Mean Absolute SHAP Value: 0.0056\n",
            "Feature: Weapon Used Cd, Summed Mean Absolute SHAP Value: 0.0055\n",
            "Feature: Date Occ, Summed Mean Absolute SHAP Value: 0.0025\n",
            "Feature: Vict Descent, Summed Mean Absolute SHAP Value: 0.0018\n",
            "Feature: Vict Sex, Summed Mean Absolute SHAP Value: 0.0013\n",
            "Feature: Time Occurred, Summed Mean Absolute SHAP Value: 0.0012\n",
            "Feature: Rpt Dist No, Summed Mean Absolute SHAP Value: 0.0011\n",
            "Feature: Vict Age Was 0, Summed Mean Absolute SHAP Value: 0.0009\n",
            "Feature: Status, Summed Mean Absolute SHAP Value: 0.0008\n",
            "Feature: Area, Summed Mean Absolute SHAP Value: 0.0002\n"
          ]
        }
      ],
      "source": [
        "true_shap_values = np.empty(12)\n",
        "true_shap_values[:7] = mean_abs_shap_values[:7]\n",
        "true_shap_values[7] = mean_abs_shap_values[7:12].sum()\n",
        "true_shap_values[8] = mean_abs_shap_values[13:91].sum()\n",
        "true_shap_values[9] = mean_abs_shap_values[92:111].sum()\n",
        "true_shap_values[10] = mean_abs_shap_values[112:116].sum()\n",
        "true_shap_values[11] = mean_abs_shap_values[117:].sum()\n",
        "true_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\", \"Status\", \"Weapon Used Cd\", \"Vict Descent\", \"Vict Sex\", \"Mocodes\"]\n",
        "sorted_true_indices = np.argsort(-true_shap_values)\n",
        "sorted_true_shap_values = true_shap_values[sorted_true_indices]\n",
        "sorted_true_feature_names = np.array(true_feature_names)[sorted_true_indices]\n",
        "\n",
        "most_important_true_feature = sorted_true_feature_names[0]\n",
        "most_important_true_value = sorted_true_shap_values[0]\n",
        "print(\"SHAP Values of Each Feature Ranked\")\n",
        "for feature, importance in zip(sorted_true_feature_names, sorted_true_shap_values):\n",
        "    print(f\"Feature: {feature}, Summed Mean Absolute SHAP Value: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqBB-TztmsbS"
      },
      "source": [
        "This confirms our expectation that Mocodes would provide the most help in determining the type of crime. This can be further strengthened by the fact that without Mocodes, we were only able to reach around 50% accuracy. Whereas with Mocodes, we could reach 65-70% accuracy in our deep learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvnTbvF9mhLR"
      },
      "source": [
        "# Part 1-2 Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "689TWUo8mK6n",
        "outputId": "b22c1557-128e-49e8-ff6b-56410a418616"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-c8e30d2c9368>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  part12_model.load_state_dict(torch.load('/content/basic_nn_model_part12.pkl', map_location=device))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BasicNN(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=297, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=256, out_features=180, bias=True)\n",
              "    (4): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.2, inplace=False)\n",
              "    (7): Linear(in_features=180, out_features=120, bias=True)\n",
              "    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=120, out_features=80, bias=True)\n",
              "    (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): Linear(in_features=80, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "part12_model = BasicNN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=2, dropout_rate=dropout_rate)\n",
        "\n",
        "# Load pre-trained weights into the model\n",
        "part12_model.load_state_dict(torch.load('basic_nn_model_part12.pkl', map_location=device))\n",
        "part12_model.to(device)\n",
        "part12_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk8Fb6dynBxn",
        "outputId": "8a49e24d-5a9e-4dbb-9af3-90f02600673c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PermutationExplainer explainer: 4097it [03:46, 17.29it/s]\n"
          ]
        }
      ],
      "source": [
        "def part12_model_predict(X):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    part12_model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = part12_model(X_tensor)\n",
        "        return torch.softmax(outputs, dim=1).cpu().numpy()  # Return probabilities\n",
        "\n",
        "explainer = shap.Explainer(part12_model_predict, batch_data)\n",
        "\n",
        "# Compute SHAP values for the batch\n",
        "shap_values = explainer(batch_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NzaOngD1lfE"
      },
      "outputs": [],
      "source": [
        "average_shap_values = np.mean(shap_values.values, axis=0)  # Shape: (297, 69)\n",
        "for target_class in range(2):\n",
        "    class_shap_values = average_shap_values[:, target_class]  # Shape: (297,)\n",
        "\n",
        "    sorted_indices = np.argsort(-np.abs(class_shap_values))  # Sort by absolute importance\n",
        "    sorted_shap_values = class_shap_values[sorted_indices]\n",
        "    sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n",
        "\n",
        "    # Plot the averaged SHAP values for this class\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(sorted_feature_names[:20], sorted_shap_values[:20])  # Top 20 features\n",
        "    plt.xlabel(\"Average SHAP Value\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.title(f\"Averaged Feature Importance for Class {target_class}\")\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"averaged_summary_plot_class_{target_class}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8B4r8lK0eKw",
        "outputId": "4f7771ce-5cfd-4727-d881-c8393bac23b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Features Across All Classes:\n",
            "Feature: Mocode_0344, Mean Absolute SHAP Value: 0.1458\n",
            "Feature: Mocode_0329, Mean Absolute SHAP Value: 0.0518\n",
            "Feature: Vict Age, Mean Absolute SHAP Value: 0.0378\n",
            "Feature: Weapon Used Cd_211.0, Mean Absolute SHAP Value: 0.0372\n",
            "Feature: Mocode_NaN, Mean Absolute SHAP Value: 0.0355\n",
            "Feature: Mocode_0325, Mean Absolute SHAP Value: 0.0250\n",
            "Feature: Weapon Used Cd_513.0, Mean Absolute SHAP Value: 0.0232\n",
            "Feature: Premise Code, Mean Absolute SHAP Value: 0.0223\n",
            "Feature: Weapon Used Cd_516.0, Mean Absolute SHAP Value: 0.0199\n",
            "Feature: Vict Age Was 0, Mean Absolute SHAP Value: 0.0197\n"
          ]
        }
      ],
      "source": [
        "mean_abs_shap_values = np.mean(np.abs(shap_values.values), axis=(0, 2))  # Shape: (297,)\n",
        "# Sort features by their mean absolute SHAP value\n",
        "sorted_indices = np.argsort(-mean_abs_shap_values)\n",
        "sorted_shap_values = mean_abs_shap_values[sorted_indices]\n",
        "sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n",
        "\n",
        "most_important_feature = sorted_feature_names[0]\n",
        "most_important_value = sorted_shap_values[0]\n",
        "\n",
        "print(\"\\nTop 10 Features Across All Classes:\")\n",
        "for feature, importance in zip(sorted_feature_names[:10], sorted_shap_values[:10]):\n",
        "    print(f\"Feature: {feature}, Mean Absolute SHAP Value: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkq44oaG1n9G",
        "outputId": "796c3ab4-1b7f-49b3-97cd-9ae51913f544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature: Mocodes, Summed Mean Absolute SHAP Value: 0.5251\n",
            "Feature: Weapon Used Cd, Summed Mean Absolute SHAP Value: 0.0700\n",
            "Feature: Vict Descent, Summed Mean Absolute SHAP Value: 0.0672\n",
            "Feature: Vict Sex, Summed Mean Absolute SHAP Value: 0.0382\n",
            "Feature: Vict Age, Summed Mean Absolute SHAP Value: 0.0378\n",
            "Feature: Premise Code, Summed Mean Absolute SHAP Value: 0.0223\n",
            "Feature: Vict Age Was 0, Summed Mean Absolute SHAP Value: 0.0197\n",
            "Feature: Status, Summed Mean Absolute SHAP Value: 0.0140\n",
            "Feature: Rpt Dist No, Summed Mean Absolute SHAP Value: 0.0118\n",
            "Feature: Date Occ, Summed Mean Absolute SHAP Value: 0.0114\n",
            "Feature: Time Occurred, Summed Mean Absolute SHAP Value: 0.0106\n",
            "Feature: Area, Summed Mean Absolute SHAP Value: 0.0031\n"
          ]
        }
      ],
      "source": [
        "true_shap_values = np.empty(12)\n",
        "true_shap_values[:7] = mean_abs_shap_values[:7]\n",
        "true_shap_values[7] = mean_abs_shap_values[7:12].sum()\n",
        "true_shap_values[8] = mean_abs_shap_values[13:91].sum()\n",
        "true_shap_values[9] = mean_abs_shap_values[92:111].sum()\n",
        "true_shap_values[10] = mean_abs_shap_values[112:116].sum()\n",
        "true_shap_values[11] = mean_abs_shap_values[117:].sum()\n",
        "true_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\", \"Status\", \"Weapon Used Cd\", \"Vict Descent\", \"Vict Sex\", \"Mocodes\"]\n",
        "sorted_true_indices = np.argsort(-true_shap_values)\n",
        "sorted_true_shap_values = true_shap_values[sorted_true_indices]\n",
        "sorted_true_feature_names = np.array(true_feature_names)[sorted_true_indices]\n",
        "\n",
        "most_important_true_feature = sorted_true_feature_names[0]\n",
        "most_important_true_value = sorted_true_shap_values[0]\n",
        "\n",
        "for feature, importance in zip(sorted_true_feature_names, sorted_true_shap_values):\n",
        "    print(f\"Feature: {feature}, Summed Mean Absolute SHAP Value: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cTYN-Lumlx8"
      },
      "source": [
        "# Feature Importance over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtwZjRZemN3X",
        "outputId": "701c2265-7ab2-47dc-cc1e-908f20c668ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-3ec26c83526f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  time_sensitive_model.load_state_dict(torch.load('/content/basic_nn_model_time_sensitive.pkl', map_location=device))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BasicNN(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=297, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=256, out_features=180, bias=True)\n",
              "    (4): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.2, inplace=False)\n",
              "    (7): Linear(in_features=180, out_features=120, bias=True)\n",
              "    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=120, out_features=80, bias=True)\n",
              "    (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): Linear(in_features=80, out_features=69, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_sensitive_model = BasicNN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size, dropout_rate=dropout_rate)\n",
        "# Load pre-trained weights into the model\n",
        "time_sensitive_model.load_state_dict(torch.load('basic_nn_model_time_sensitive.pkl', map_location=device))\n",
        "time_sensitive_model.to(device)\n",
        "time_sensitive_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu9YFAIOnQln",
        "outputId": "eb8009dc-1591-4eab-c3e5-f0c679c11713"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PermutationExplainer explainer: 4097it [04:36, 14.24it/s]\n"
          ]
        }
      ],
      "source": [
        "def time_sensitive_model_predict(X):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    time_sensitive_model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = time_sensitive_model(X_tensor)\n",
        "        return torch.softmax(outputs, dim=1).cpu().numpy()  # Return probabilities\n",
        "\n",
        "explainer = shap.Explainer(time_sensitive_model_predict, batch_data)\n",
        "\n",
        "# Compute SHAP values for the batch\n",
        "shap_values = explainer(batch_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slEdfone1rLR"
      },
      "outputs": [],
      "source": [
        "average_shap_values = np.mean(shap_values.values, axis=0)  # Shape: (297, 69)\n",
        "for target_class in range(69):\n",
        "    class_shap_values = average_shap_values[:, target_class]  # Shape: (297,)\n",
        "\n",
        "    sorted_indices = np.argsort(-np.abs(class_shap_values))  # Sort by absolute importance\n",
        "    sorted_shap_values = class_shap_values[sorted_indices]\n",
        "    sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n",
        "\n",
        "    # Plot the averaged SHAP values for this class\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(sorted_feature_names[:20], sorted_shap_values[:20])  # Top 20 features\n",
        "    plt.xlabel(\"Average SHAP Value\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.title(f\"Averaged Feature Importance for Class {target_class}\")\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"averaged_summary_plot_class_{target_class}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIOBls0N0kaq",
        "outputId": "559bbe71-7875-4f68-ea7e-659a9b5eae91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Features Across All Classes:\n",
            "Feature: Premise Code, Mean Absolute SHAP Value: 0.0068\n",
            "Feature: Mocode_0344, Mean Absolute SHAP Value: 0.0065\n",
            "Feature: Vict Age, Mean Absolute SHAP Value: 0.0052\n",
            "Feature: Mocode_0329, Mean Absolute SHAP Value: 0.0033\n",
            "Feature: Weapon Used Cd_211.0, Mean Absolute SHAP Value: 0.0028\n",
            "Feature: Date Occ, Mean Absolute SHAP Value: 0.0024\n",
            "Feature: Mocode_0416, Mean Absolute SHAP Value: 0.0017\n",
            "Feature: Mocode_NaN, Mean Absolute SHAP Value: 0.0016\n",
            "Feature: Rpt Dist No, Mean Absolute SHAP Value: 0.0014\n",
            "Feature: Mocode_0325, Mean Absolute SHAP Value: 0.0012\n"
          ]
        }
      ],
      "source": [
        "mean_abs_shap_values = np.mean(np.abs(shap_values.values), axis=(0, 2))  # Shape: (297,)\n",
        "# Sort features by their mean absolute SHAP value\n",
        "sorted_indices = np.argsort(-mean_abs_shap_values)\n",
        "sorted_shap_values = mean_abs_shap_values[sorted_indices]\n",
        "sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n",
        "\n",
        "most_important_feature = sorted_feature_names[0]\n",
        "most_important_value = sorted_shap_values[0]\n",
        "\n",
        "print(\"\\nTop 10 Features Across All Classes:\")\n",
        "for feature, importance in zip(sorted_feature_names[:10], sorted_shap_values[:10]):\n",
        "    print(f\"Feature: {feature}, Mean Absolute SHAP Value: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg1-7fL81tmJ",
        "outputId": "f12a205d-a405-4d9f-9907-cdef9ff8b8f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature: Mocodes, Summed Mean Absolute SHAP Value: 0.0341\n",
            "Feature: Premise Code, Summed Mean Absolute SHAP Value: 0.0068\n",
            "Feature: Weapon Used Cd, Summed Mean Absolute SHAP Value: 0.0054\n",
            "Feature: Vict Age, Summed Mean Absolute SHAP Value: 0.0052\n",
            "Feature: Date Occ, Summed Mean Absolute SHAP Value: 0.0024\n",
            "Feature: Vict Descent, Summed Mean Absolute SHAP Value: 0.0018\n",
            "Feature: Rpt Dist No, Summed Mean Absolute SHAP Value: 0.0014\n",
            "Feature: Vict Sex, Summed Mean Absolute SHAP Value: 0.0013\n",
            "Feature: Time Occurred, Summed Mean Absolute SHAP Value: 0.0010\n",
            "Feature: Status, Summed Mean Absolute SHAP Value: 0.0008\n",
            "Feature: Vict Age Was 0, Summed Mean Absolute SHAP Value: 0.0007\n",
            "Feature: Area, Summed Mean Absolute SHAP Value: 0.0001\n"
          ]
        }
      ],
      "source": [
        "true_shap_values = np.empty(12)\n",
        "true_shap_values[:7] = mean_abs_shap_values[:7]\n",
        "true_shap_values[7] = mean_abs_shap_values[7:12].sum()\n",
        "true_shap_values[8] = mean_abs_shap_values[13:91].sum()\n",
        "true_shap_values[9] = mean_abs_shap_values[92:111].sum()\n",
        "true_shap_values[10] = mean_abs_shap_values[112:116].sum()\n",
        "true_shap_values[11] = mean_abs_shap_values[117:].sum()\n",
        "true_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\", \"Status\", \"Weapon Used Cd\", \"Vict Descent\", \"Vict Sex\", \"Mocodes\"]\n",
        "sorted_true_indices = np.argsort(-true_shap_values)\n",
        "sorted_true_shap_values = true_shap_values[sorted_true_indices]\n",
        "sorted_true_feature_names = np.array(true_feature_names)[sorted_true_indices]\n",
        "\n",
        "most_important_true_feature = sorted_true_feature_names[0]\n",
        "most_important_true_value = sorted_true_shap_values[0]\n",
        "\n",
        "for feature, importance in zip(sorted_true_feature_names, sorted_true_shap_values):\n",
        "    print(f\"Feature: {feature}, Summed Mean Absolute SHAP Value: {importance:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
