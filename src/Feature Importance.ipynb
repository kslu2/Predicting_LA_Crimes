{"cells":[{"cell_type":"markdown","metadata":{"id":"Ng8Id0_nYrdA"},"source":["# Feature Importance\n","This python file will be to perform Feature Importance using Shapley values to determine the ranking of features in terms of how much they influence the model in effectively predicting the crime codes. The file will start with preprocessing the data similar to previous learning files then performing feature importance with Shapley values\n","\n","\n","**Authors:** Kevin Lu, Shrusti Jain, Smeet Patel, Taobo Liao\n"]},{"cell_type":"markdown","metadata":{"id":"oIzSxXnoLlLO"},"source":["# Imports and Graph Configurations"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1733603607070,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"vWRR1GNOJUnp"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import time\n","import datetime\n","import tensorflow as tf\n","import random\n","import matplotlib\n","import torch\n","import torch.nn as nn\n","#%matplotlib notebook\n","import matplotlib.pyplot as plt\n","import scipy.stats\n","import matplotlib.offsetbox as offsetbox\n","from matplotlib.ticker import StrMethodFormatter\n","from google.colab import drive\n","from sklearn import datasets, linear_model"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3265,"status":"ok","timestamp":1733603610625,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"KyP1o-VJKjGT","outputId":"bd5c2a72-3f31-4857-a5e7-0bc7b8b009da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.46.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.6)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.2)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.1.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"]}],"source":["!pip install shap\n","import shap"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1733603610626,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"9TtAWe0_JWPk"},"outputs":[],"source":["#for some reason, this needs to be in a separate cell\n","params={\n","    \"font.size\":15,\n","    \"lines.linewidth\":5,\n","}\n","plt.rcParams.update(params)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36181,"status":"ok","timestamp":1733603646797,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"90N4am7rJXpI","outputId":"11dc1c2b-0fb2-4a7e-ea98-10f18daac55a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1enR3DLH7iDuI0mG8rV3Z21tPhdZZRXOv\n","From (redirected): https://drive.google.com/uc?id=1enR3DLH7iDuI0mG8rV3Z21tPhdZZRXOv&confirm=t&uuid=427909fb-a13b-4876-b671-c0c06a459393\n","To: /content/train.pkl\n","100% 224M/224M [00:07<00:00, 30.8MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1zeyltSH_KaN0qQCRCiZR8kXOG6VUXU9T\n","To: /content/debug.pkl\n","100% 11.2M/11.2M [00:00<00:00, 147MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1GOlOSBBJdWWdh8z2oS19aEROm-3oTB4d\n","To: /content/basic_nn_model.pkl\n","100% 658k/658k [00:00<00:00, 88.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1_tvxGoEQEMFialDlTOjGmLaU8xz7_Yom\n","To: /content/basic_nn_model_time_sensitive.pkl\n","100% 659k/659k [00:00<00:00, 127MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1enYGeEeWNFDr-qHQuCNnb4q6yV7O9cpg\n","To: /content/basic_nn_model_part12.pkl\n","100% 637k/637k [00:00<00:00, 104MB/s]\n"]}],"source":["#download train and debug and models\n","!gdown 1enR3DLH7iDuI0mG8rV3Z21tPhdZZRXOv\n","!gdown 1zeyltSH_KaN0qQCRCiZR8kXOG6VUXU9T\n","!gdown 1GOlOSBBJdWWdh8z2oS19aEROm-3oTB4d\n","!gdown 1_tvxGoEQEMFialDlTOjGmLaU8xz7_Yom\n","!gdown 1enYGeEeWNFDr-qHQuCNnb4q6yV7O9cpg"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1733603646798,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"0cV0982DwPbA"},"outputs":[],"source":["# Basic Neural Network with 3 hidden layers, BatchNorm and dropout\n","class BasicNN(nn.Module):\n","    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate):\n","        super(BasicNN, self).__init__()\n","        self.layers = nn.Sequential(\n","            # Input layer\n","            nn.Linear(input_size, hidden_sizes[0]),\n","            nn.BatchNorm1d(hidden_sizes[0]),\n","            nn.ReLU(),\n","\n","            # Hidden Layer 1\n","            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n","            nn.BatchNorm1d(hidden_sizes[1]),\n","            nn.ReLU(),\n","            nn.Dropout(p=dropout_rate),\n","\n","            # Hidden Layer 2\n","            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n","            nn.BatchNorm1d(hidden_sizes[2]),\n","            nn.ReLU(),\n","\n","            # Hidden Layer 3 (New layer added)\n","            nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n","            nn.BatchNorm1d(hidden_sizes[3]),\n","            nn.ReLU(),\n","\n","            # Output layer\n","            nn.Linear(hidden_sizes[3], output_size),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2218,"status":"ok","timestamp":1733603649006,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"47u4qdNrJZrX","outputId":"75076a65-8cba-47df-920d-559bdb21000a"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-23-808ff7c01299>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('/content/basic_nn_model.pkl', map_location=device))\n"]},{"output_type":"execute_result","data":{"text/plain":["BasicNN(\n","  (layers): Sequential(\n","    (0): Linear(in_features=297, out_features=256, bias=True)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=256, out_features=180, bias=True)\n","    (4): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Dropout(p=0.2, inplace=False)\n","    (7): Linear(in_features=180, out_features=120, bias=True)\n","    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU()\n","    (10): Linear(in_features=120, out_features=80, bias=True)\n","    (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU()\n","    (13): Linear(in_features=80, out_features=69, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":23}],"source":["# Load dataframe objects from the Deep Learning notebook\n","crime_df_train = pd.read_pickle('/content/train.pkl')\n","crime_df_debug = pd.read_pickle('/content/debug.pkl')\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","input_size = 297\n","hidden_sizes = [256, 180, 120, 80]\n","output_size = 69\n","learning_rate = 1e-3\n","dropout_rate = 0.2\n","milestones = [10, 15]\n","\n","model = BasicNN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size, dropout_rate=dropout_rate)\n","\n","# Load pre-trained weights into the model\n","model.load_state_dict(torch.load('/content/basic_nn_model.pkl', map_location=device))\n","model.to(device)\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"aANIvkfoKc_r"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1733603654443,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"reaZRUbYKcrb","outputId":"ea789484-4e36-4bdf-8714-226f27ce3a3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Status  Weapon Used Cd Vict Descent Vict Sex  Vict Age              Mocodes  \\\n","0     AA             NaN            O        M         0                  NaN   \n","1     IC             NaN            O        M        47       1822 1402 0344   \n","2     IC             NaN            X        X        19            0344 1251   \n","3     IC             NaN            O        M        19            0325 1501   \n","4     IC             NaN            H        M        28  1822 1501 0930 2004   \n","\n","   Crm Cd  Part 1-2  Rpt Dist No  AREA  TIME OCC   DATE OCC  Premis Cd  \\\n","0     510         1          784     7      2130 2020-03-01      101.0   \n","1     330         1          182     1      1800 2020-02-08      128.0   \n","2     480         1          356     3      1700 2020-11-04      502.0   \n","3     343         1          964     9      2037 2020-03-10      405.0   \n","4     354         2          666     6      1200 2020-08-17      102.0   \n","\n","   Vict Age Was 0  \n","0               1  \n","1               0  \n","2               0  \n","3               0  \n","4               0  "],"text/html":["\n","  <div id=\"df-66638a1e-6e73-4fde-84fb-4ddd04c346be\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Status</th>\n","      <th>Weapon Used Cd</th>\n","      <th>Vict Descent</th>\n","      <th>Vict Sex</th>\n","      <th>Vict Age</th>\n","      <th>Mocodes</th>\n","      <th>Crm Cd</th>\n","      <th>Part 1-2</th>\n","      <th>Rpt Dist No</th>\n","      <th>AREA</th>\n","      <th>TIME OCC</th>\n","      <th>DATE OCC</th>\n","      <th>Premis Cd</th>\n","      <th>Vict Age Was 0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AA</td>\n","      <td>NaN</td>\n","      <td>O</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>510</td>\n","      <td>1</td>\n","      <td>784</td>\n","      <td>7</td>\n","      <td>2130</td>\n","      <td>2020-03-01</td>\n","      <td>101.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>IC</td>\n","      <td>NaN</td>\n","      <td>O</td>\n","      <td>M</td>\n","      <td>47</td>\n","      <td>1822 1402 0344</td>\n","      <td>330</td>\n","      <td>1</td>\n","      <td>182</td>\n","      <td>1</td>\n","      <td>1800</td>\n","      <td>2020-02-08</td>\n","      <td>128.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>IC</td>\n","      <td>NaN</td>\n","      <td>X</td>\n","      <td>X</td>\n","      <td>19</td>\n","      <td>0344 1251</td>\n","      <td>480</td>\n","      <td>1</td>\n","      <td>356</td>\n","      <td>3</td>\n","      <td>1700</td>\n","      <td>2020-11-04</td>\n","      <td>502.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>IC</td>\n","      <td>NaN</td>\n","      <td>O</td>\n","      <td>M</td>\n","      <td>19</td>\n","      <td>0325 1501</td>\n","      <td>343</td>\n","      <td>1</td>\n","      <td>964</td>\n","      <td>9</td>\n","      <td>2037</td>\n","      <td>2020-03-10</td>\n","      <td>405.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>IC</td>\n","      <td>NaN</td>\n","      <td>H</td>\n","      <td>M</td>\n","      <td>28</td>\n","      <td>1822 1501 0930 2004</td>\n","      <td>354</td>\n","      <td>2</td>\n","      <td>666</td>\n","      <td>6</td>\n","      <td>1200</td>\n","      <td>2020-08-17</td>\n","      <td>102.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66638a1e-6e73-4fde-84fb-4ddd04c346be')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-66638a1e-6e73-4fde-84fb-4ddd04c346be button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-66638a1e-6e73-4fde-84fb-4ddd04c346be');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0bb3fecb-221c-4d8f-8e17-59ddbcb9e94a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bb3fecb-221c-4d8f-8e17-59ddbcb9e94a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0bb3fecb-221c-4d8f-8e17-59ddbcb9e94a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"crime_selected_df"}},"metadata":{},"execution_count":24}],"source":["# Add a binary column indicating if Vict Age is 0\n","crime_df_train['Vict Age Was 0'] = (crime_df_train['Vict Age'] == 0).astype(int)\n","\n","# Select relevant columns for analysis\n","selected_columns = [\n","    'Status',\n","    'Weapon Used Cd',\n","    'Vict Descent',\n","    'Vict Sex',\n","    'Vict Age',\n","    'Mocodes',\n","    'Crm Cd',\n","    'Part 1-2',\n","    'Rpt Dist No',\n","    'AREA',\n","    'TIME OCC',\n","    'DATE OCC',\n","    'Premis Cd',\n","    'Vict Age Was 0'\n","]\n","\n","# Create a DataFrame with only the selected columns\n","crime_selected_df = crime_df_train[selected_columns]\n","crime_selected_df.head()"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1733603654722,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"XTQH81G1y4D9"},"outputs":[],"source":["counts = crime_selected_df['Crm Cd'].value_counts()\n","codes = counts[counts>500].index.tolist()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23481,"status":"ok","timestamp":1733603678198,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"DpVL6kiAy6WX","outputId":"64cce48c-a940-4a07-a365-2e246ca76440"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-0f73308a5fa6>:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  crime_selected_df['TIME OCC'] = crime_selected_df['TIME OCC'].apply(convert_to_minutes)\n"]},{"output_type":"stream","name":"stdout","text":["297\n"]}],"source":["def convert_to_minutes(military_time):\n","    \"\"\"\n","    Convert military time to minutes from midnight.\n","\n","    Parameters:\n","    military_time (int): Time in military format, e.g., 2305 for 11:05 PM.\n","\n","    Returns:\n","    int: Total minutes from midnight.\n","    \"\"\"\n","    # Ensure the time is a four-digit string (e.g., '2305')\n","    military_time = str(military_time).zfill(4)\n","\n","    # Extract hours and minutes from the string\n","    hours = int(military_time[:2])\n","    minutes = int(military_time[2:])\n","\n","    # Calculate and return the total minutes from midnight\n","    total_minutes = hours * 60 + minutes\n","    return total_minutes\n","\n","# Apply the convert_to_minutes function to 'TIME OCC' column\n","crime_selected_df['TIME OCC'] = crime_selected_df['TIME OCC'].apply(convert_to_minutes)\n","\n","# Function to one-hot encode specified categorical columns\n","def one_hot_encode(df, columns):\n","    \"\"\"\n","    Apply one-hot encoding to specified columns in the DataFrame.\n","\n","    Parameters:\n","    df (pd.DataFrame): The input DataFrame.\n","    columns (list): List of columns to one-hot encode.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame with one-hot encoded columns.\n","    \"\"\"\n","    labels = []\n","    for column in columns:\n","\n","        # Create one-hot encoded columns for each category in the column\n","        one_hot = pd.get_dummies(df[column], prefix=column)\n","\n","        # Convert one-hot encoded DataFrame to integer type for compactness\n","        one_hot = one_hot.astype(int)\n","\n","        # Replace the original column with the one-hot encoded columns\n","        df[column] = one_hot.values.tolist()\n","\n","        # Add corresponding labels to labels\n","        labels += one_hot.columns.to_list()\n","    return df, labels\n","\n","# Function to multi-hot encode 'Mocodes' column where each row may contain multiple codes\n","def multi_hot_encode_mocodes(df):\n","    \"\"\"\n","    Multi-hot encode the 'Mocodes' column.\n","\n","    Parameters:\n","    df (pd.DataFrame): The input DataFrame.\n","\n","    Returns:\n","    pd.DataFrame: DataFrame with 'Mocodes' column as multi-hot encoded vectors.\n","    \"\"\"\n","    # Initialize a set of all unique Mocodes for multi-hot encoding\n","    mocode_counts = {}\n","\n","    # Populate the set with unique Mocodes from each row (handling NaN values)\n","    for mocode_str in df['Mocodes'].dropna():\n","        mocode_str = str(mocode_str)\n","        mocodes = mocode_str.split(' ')\n","        for mocode in mocodes:\n","            mocode_counts[mocode] = mocode_counts.get(mocode, 0) + 1\n","\n","    filtered_mocodes = {mocode for mocode, count in mocode_counts.items() if count > 1000}\n","    filtered_mocodes.add('NaN')\n","    mocode_index = {mocode: idx for idx, mocode in enumerate(sorted(filtered_mocodes))}\n","\n","    # Define a helper function to encode Mocodes into a binary vector\n","    def encode_mocodes(mocode_str):\n","        # Split the Mocode string into individual codes, or set to 'NaN' if empty\n","        if isinstance(mocode_str, str):\n","            mocodes = mocode_str.split()\n","        else:\n","            mocodes = ['NaN']\n","\n","        # Initialize a zero vector and set indices for each Mocode found\n","        encoded_vector = [0] * len(mocode_index)\n","        for mocode in mocodes:\n","            if mocode in mocode_index:\n","                encoded_vector[mocode_index[mocode]] = 1\n","        return encoded_vector\n","\n","    # Apply the encoding function to the 'Mocodes' column\n","    df['Mocodes'] = df['Mocodes'].apply(encode_mocodes)\n","    mocodes = [f'Mocode_{mocode}' for mocode in list(mocode_index.keys())]\n","    return df, mocodes\n","\n","# Specify columns to one-hot encode\n","columns_to_encode = ['Status', 'Vict Descent', 'Vict Sex', 'Weapon Used Cd']\n","\n","# Apply one-hot encoding to specified columns and store the result in a new DataFrame\n","crime_selected_one_hot_df, labels = one_hot_encode(crime_selected_df.copy(), columns_to_encode)\n","\n","crime_selected_one_hot_df, mocodes = multi_hot_encode_mocodes(crime_selected_one_hot_df.copy())\n","crime_selected_one_hot_df[\"Part 1-2\"] -= 1\n","crime_selected_one_hot_df.head()\n","ungrouped_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\"] + labels + mocodes\n","print(len(ungrouped_feature_names))"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":28472,"status":"ok","timestamp":1733603706663,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"pRAf8c2oy91X"},"outputs":[],"source":["# Create the final X dataset for feature importance after preprocessing\n","crime_selected_one_hot_df['DATE OCC INT'] = crime_selected_one_hot_df['DATE OCC'].astype('int64') // (10**9 * 60 * 60 * 24)\n","crime_selected_one_hot_df [['Status','Weapon Used Cd','Vict Descent','Vict Sex','Vict Age','Crm Cd','Part 1-2','Rpt Dist No','AREA','TIME OCC','DATE OCC','Premis Cd','Vict Age Was 0']].isna().any()\n","crime_selected_one_hot_df['Premis Cd'] = crime_selected_one_hot_df['Premis Cd'].fillna(0)\n","non_list = crime_selected_one_hot_df[['DATE OCC INT','Vict Age Was 0', 'Vict Age', 'Rpt Dist No', 'AREA', 'TIME OCC','Premis Cd']].to_numpy(dtype=np.float32)\n","X = np.concatenate([non_list, np.array(crime_selected_one_hot_df['Status'].to_list()), np.array(crime_selected_one_hot_df['Weapon Used Cd'].to_list()), np.array(crime_selected_one_hot_df['Vict Descent'].to_list()), np.array(crime_selected_one_hot_df['Vict Sex'].to_list()), np.array(crime_selected_one_hot_df['Mocodes'].to_list())], axis=1)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1733603706944,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"-x3m1tISz30w","outputId":"821baed4-e855-4a7e-8730-79d86f210246"},"outputs":[{"output_type":"stream","name":"stdout","text":["One-hot encoded Y shape: (986500, 69)\n"]}],"source":["# Creating the Y dataset for feature importance evaluation\n","Y = crime_selected_one_hot_df['Crm Cd'].to_numpy()\n","unique_classes = np.unique(Y)\n","counts = crime_selected_df['Crm Cd'].value_counts()\n","retained_classes = counts[counts>500].index.tolist()\n","removed_classes = counts[counts<=500].index.tolist()\n","class_to_index = {cls: idx for idx, cls in enumerate(retained_classes)}\n","class_to_index.update({cls: len(retained_classes) for cls in removed_classes})\n","Y_indices = np.array([class_to_index[cls] for cls in Y])\n","size = crime_selected_one_hot_df.shape[0]\n","weights = counts[counts>500].to_list()\n","weights.append(counts[counts<=500].sum())\n","weights = (np.sqrt(crime_selected_one_hot_df['Crm Cd'].shape[0]/np.array(weights)))/10\n","Y_one_hot = np.zeros((len(Y), len(retained_classes)+1), dtype=np.float32)\n","Y_one_hot[np.arange(len(Y)), Y_indices] = 1\n","Y_part12 = crime_selected_one_hot_df['Part 1-2'].to_numpy()\n","print(f\"One-hot encoded Y shape: {Y_one_hot.shape}\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1636,"status":"ok","timestamp":1733603708577,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"},"user_tz":360},"id":"gnmL2M0Z048z","outputId":"ff4c7161-6b53-4d37-dfff-3531223f0d94"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([986500, 297])\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Initializing our dataset for x features and y labels\n","class CrimeDataset(Dataset):\n","    def __init__(self, features, crimes):\n","        self.features = features\n","        self.labels = crimes\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        x = self.features[idx]\n","        y = self.labels[idx]\n","        return x, y\n","\n","# Utilize T4 GPU for faster computation\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","X_torch = torch.tensor(X, dtype=torch.float32).to(device)\n","print(X_torch.shape)\n","Y_torch = torch.tensor(Y_one_hot, dtype=torch.float32).to(device)\n","dataset = CrimeDataset(X_torch, Y_torch)\n","\n","# Initialization of our dataset will be 70/20/10 split being training, validation, and test respectively\n","train_set, val_set, test_set = torch.utils.data.random_split(dataset, [.70, .20, .10])\n","train_loader = DataLoader(train_set, batch_size=4096, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=4096, shuffle=False)\n","test_loader = DataLoader(test_set, batch_size=4096, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"SFNyyPVIz-qP"},"source":["# Feature Importance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2XMmEfB0GDM","executionInfo":{"status":"ok","timestamp":1733601472030,"user_tz":360,"elapsed":830042,"user":{"displayName":"Kevin Lu","userId":"02049741947617500154"}},"outputId":"f1cb0764-1a6f-40db-efb9-7b46e3af494a"},"outputs":[{"output_type":"stream","name":"stderr","text":["PermutationExplainer explainer: 4097it [13:48,  4.90it/s]\n"]}],"source":["def model_predict(X):\n","    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(X_tensor)\n","        return torch.softmax(outputs, dim=1).cpu().numpy()  # Return probabilities\n","\n","# Select a single batch of data from the training set for SHAP analysis\n","batch_data, _ = next(iter(train_loader))\n","batch_data = batch_data.cpu().numpy()\n","\n","explainer = shap.Explainer(model_predict, batch_data)\n","\n","# Compute SHAP values for the batch\n","shap_values = explainer(batch_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1yp6yJo_4yn","executionInfo":{"status":"ok","timestamp":1733601472030,"user_tz":360,"elapsed":6,"user":{"displayName":"Kevin Lu","userId":"02049741947617500154"}},"outputId":"803e516c-2dcd-4473-ecbe-abff5e185b27"},"outputs":[{"output_type":"stream","name":"stdout","text":["<module 'shap' from '/usr/local/lib/python3.10/dist-packages/shap/__init__.py'>\n"]}],"source":["print(shap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T2lv_85K2nZP"},"outputs":[],"source":["average_shap_values = np.mean(shap_values.values, axis=0)  # Shape: (297, 69)\n","for target_class in range(69):\n","    class_shap_values = average_shap_values[:, target_class]  # Shape: (297,)\n","\n","    sorted_indices = np.argsort(-np.abs(class_shap_values))  # Sort by absolute importance\n","    sorted_shap_values = class_shap_values[sorted_indices]\n","    sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n","\n","    # Plot the averaged SHAP values for this class\n","    plt.figure(figsize=(10, 6))\n","    plt.barh(sorted_feature_names[:20], sorted_shap_values[:20])  # Top 20 features\n","    plt.xlabel(\"Average SHAP Value\")\n","    plt.ylabel(\"Feature\")\n","    plt.title(f\"Averaged Feature Importance for Class {target_class}\")\n","    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n","    plt.tight_layout()\n","    plt.savefig(f\"averaged_summary_plot_class_{target_class}.png\")\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"EwjILz10CZrb"},"source":["Actual feature descriptions:\n","* Feature 1: Date Occured\n","* Feature 2: Vict Age Was 0 (Unlisted)\n","* Feature 3: Vict Age\n","* Feature 4: Rpt Dist No\n","* Feature 5: Area\n","* Feature 6: Time Occurred\n","* Feature 7: Premise Code\n","* Features 8-13: Status\n","* Features 14-92: Weapon Used Cd\n","* Features 93-112: Vict Descent\n","* Features 113-117: Vict Sex\n","* Features 118-297: Mocodes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9sWOJcAS6Qwc","executionInfo":{"status":"ok","timestamp":1733601772326,"user_tz":360,"elapsed":1727,"user":{"displayName":"Kevin Lu","userId":"02049741947617500154"}},"outputId":"b1ffb239-7f51-49a5-81df-7b613eca2681"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Top 10 Features Across All Classes:\n","Feature: Feature 7, Mean Absolute SHAP Value: 0.0069\n","Feature: Feature 143, Mean Absolute SHAP Value: 0.0064\n","Feature: Feature 3, Mean Absolute SHAP Value: 0.0056\n","Feature: Feature 136, Mean Absolute SHAP Value: 0.0030\n","Feature: Feature 75, Mean Absolute SHAP Value: 0.0027\n","Feature: Feature 1, Mean Absolute SHAP Value: 0.0023\n","Feature: Feature 168, Mean Absolute SHAP Value: 0.0019\n","Feature: Feature 297, Mean Absolute SHAP Value: 0.0019\n","Feature: Feature 6, Mean Absolute SHAP Value: 0.0013\n","Feature: Feature 279, Mean Absolute SHAP Value: 0.0011\n"]}],"source":["mean_abs_shap_values = np.mean(np.abs(shap_values.values), axis=(0, 2))  # Shape: (297,)\n","# Sort features by their mean absolute SHAP value\n","sorted_indices = np.argsort(-mean_abs_shap_values)\n","sorted_shap_values = mean_abs_shap_values[sorted_indices]\n","sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n","\n","most_important_feature = sorted_feature_names[0]\n","most_important_value = sorted_shap_values[0]\n","\n","print(\"\\nTop 10 Features Across All Classes:\")\n","for feature, importance in zip(sorted_feature_names[:10], sorted_shap_values[:10]):\n","    print(f\"Feature: {feature}, Mean Absolute SHAP Value: {importance:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"zRY03qDnV8zI"},"source":["From this trial, we can see that most of the important features are Mocodes. This makes sense because mocodes provides a detailed description of the environment of the crime scene before it happens. Such as \"Stranger\" or \"Domestic Violence\" etc."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCRlC5AzFZMq","executionInfo":{"status":"ok","timestamp":1733601862794,"user_tz":360,"elapsed":50,"user":{"displayName":"Kevin Lu","userId":"02049741947617500154"}},"outputId":"e8c8643c-2e45-4072-ebee-e0e8eb16b1a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["SHAP Values of Each Feature Ranked\n","Feature: Mocodes, Summed Mean Absolute SHAP Value: 0.0322\n","Feature: Premise Code, Summed Mean Absolute SHAP Value: 0.0069\n","Feature: Vict Age, Summed Mean Absolute SHAP Value: 0.0056\n","Feature: Weapon Used Cd, Summed Mean Absolute SHAP Value: 0.0056\n","Feature: Date Occ, Summed Mean Absolute SHAP Value: 0.0023\n","Feature: Vict Descent, Summed Mean Absolute SHAP Value: 0.0017\n","Feature: Vict Sex, Summed Mean Absolute SHAP Value: 0.0013\n","Feature: Time Occurred, Summed Mean Absolute SHAP Value: 0.0013\n","Feature: Rpt Dist No, Summed Mean Absolute SHAP Value: 0.0011\n","Feature: Vict Age Was 0, Summed Mean Absolute SHAP Value: 0.0009\n","Feature: Status, Summed Mean Absolute SHAP Value: 0.0008\n","Feature: Area, Summed Mean Absolute SHAP Value: 0.0002\n"]}],"source":["true_shap_values = np.empty(12)\n","true_shap_values[:7] = mean_abs_shap_values[:7]\n","true_shap_values[7] = mean_abs_shap_values[7:12].sum()\n","true_shap_values[8] = mean_abs_shap_values[13:91].sum()\n","true_shap_values[9] = mean_abs_shap_values[92:111].sum()\n","true_shap_values[10] = mean_abs_shap_values[112:116].sum()\n","true_shap_values[11] = mean_abs_shap_values[117:].sum()\n","true_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\", \"Status\", \"Weapon Used Cd\", \"Vict Descent\", \"Vict Sex\", \"Mocodes\"]\n","sorted_true_indices = np.argsort(-true_shap_values)\n","sorted_true_shap_values = true_shap_values[sorted_true_indices]\n","sorted_true_feature_names = np.array(true_feature_names)[sorted_true_indices]\n","\n","most_important_true_feature = sorted_true_feature_names[0]\n","most_important_true_value = sorted_true_shap_values[0]\n","print(\"SHAP Values of Each Feature Ranked\")\n","for feature, importance in zip(sorted_true_feature_names, sorted_true_shap_values):\n","    print(f\"Feature: {feature}, Summed Mean Absolute SHAP Value: {importance:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"zqBB-TztmsbS"},"source":["This confirms our expectation that Mocodes would provide the most help in determining the type of crime. This can be further strengthened by the fact that without Mocodes, we were only able to reach around 50% accuracy. Whereas with Mocodes, we could reach 65-70% accuracy in our deep learning model."]},{"cell_type":"markdown","metadata":{"id":"JvnTbvF9mhLR"},"source":["# Part 1-2 Feature Importance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"689TWUo8mK6n","executionInfo":{"status":"ok","timestamp":1733601502634,"user_tz":360,"elapsed":124,"user":{"displayName":"Kevin Lu","userId":"02049741947617500154"}},"outputId":"a84cc829-231d-48a0-d885-175e4f31fbbf"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-18-c8e30d2c9368>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  part12_model.load_state_dict(torch.load('/content/basic_nn_model_part12.pkl', map_location=device))\n"]},{"output_type":"execute_result","data":{"text/plain":["BasicNN(\n","  (layers): Sequential(\n","    (0): Linear(in_features=297, out_features=256, bias=True)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=256, out_features=180, bias=True)\n","    (4): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Dropout(p=0.2, inplace=False)\n","    (7): Linear(in_features=180, out_features=120, bias=True)\n","    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU()\n","    (10): Linear(in_features=120, out_features=80, bias=True)\n","    (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU()\n","    (13): Linear(in_features=80, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":18}],"source":["part12_model = BasicNN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=2, dropout_rate=dropout_rate)\n","\n","# Load pre-trained weights into the model\n","part12_model.load_state_dict(torch.load('/content/basic_nn_model_part12.pkl', map_location=device))\n","part12_model.to(device)\n","part12_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hk8Fb6dynBxn","executionInfo":{"status":"ok","timestamp":1733603087386,"user_tz":360,"elapsed":535532,"user":{"displayName":"Kevin Lu","userId":"02049741947617500154"}},"outputId":"f6f0cb17-e90b-4be9-bc9a-dbaff03940b1"},"outputs":[{"output_type":"stream","name":"stderr","text":["PermutationExplainer explainer: 4097it [08:55,  7.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Feature: Mocodes, Summed Mean Absolute SHAP Value: 0.0322\n","Feature: Premise Code, Summed Mean Absolute SHAP Value: 0.0069\n","Feature: Vict Age, Summed Mean Absolute SHAP Value: 0.0056\n","Feature: Weapon Used Cd, Summed Mean Absolute SHAP Value: 0.0056\n","Feature: Date Occ, Summed Mean Absolute SHAP Value: 0.0023\n","Feature: Vict Descent, Summed Mean Absolute SHAP Value: 0.0017\n","Feature: Vict Sex, Summed Mean Absolute SHAP Value: 0.0013\n","Feature: Time Occurred, Summed Mean Absolute SHAP Value: 0.0013\n","Feature: Rpt Dist No, Summed Mean Absolute SHAP Value: 0.0011\n","Feature: Vict Age Was 0, Summed Mean Absolute SHAP Value: 0.0009\n","Feature: Status, Summed Mean Absolute SHAP Value: 0.0008\n","Feature: Area, Summed Mean Absolute SHAP Value: 0.0002\n"]}],"source":["def part12_model_predict(X):\n","    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n","    part12_model.eval()\n","    with torch.no_grad():\n","        outputs = part12_model(X_tensor)\n","        return torch.softmax(outputs, dim=1).cpu().numpy()  # Return probabilities\n","\n","# Select a single batch of data from the training set for SHAP analysis\n","batch_data, _ = next(iter(train_loader))\n","batch_data = batch_data.cpu().numpy()\n","\n","explainer = shap.Explainer(part12_model_predict, batch_data)\n","\n","# Compute SHAP values for the batch\n","shap_values = explainer(batch_data)"]},{"cell_type":"code","source":["average_shap_values = np.mean(shap_values.values, axis=0)  # Shape: (297, 69)\n","for target_class in range(69):\n","    class_shap_values = average_shap_values[:, target_class]  # Shape: (297,)\n","\n","    sorted_indices = np.argsort(-np.abs(class_shap_values))  # Sort by absolute importance\n","    sorted_shap_values = class_shap_values[sorted_indices]\n","    sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n","\n","    # Plot the averaged SHAP values for this class\n","    plt.figure(figsize=(10, 6))\n","    plt.barh(sorted_feature_names[:20], sorted_shap_values[:20])  # Top 20 features\n","    plt.xlabel(\"Average SHAP Value\")\n","    plt.ylabel(\"Feature\")\n","    plt.title(f\"Averaged Feature Importance for Class {target_class}\")\n","    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n","    plt.tight_layout()\n","    plt.savefig(f\"averaged_summary_plot_class_{target_class}.png\")\n","    plt.close()"],"metadata":{"id":"7NzaOngD1lfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true_shap_values = np.empty(12)\n","true_shap_values[:7] = mean_abs_shap_values[:7]\n","true_shap_values[7] = mean_abs_shap_values[7:12].sum()\n","true_shap_values[8] = mean_abs_shap_values[13:91].sum()\n","true_shap_values[9] = mean_abs_shap_values[92:111].sum()\n","true_shap_values[10] = mean_abs_shap_values[112:116].sum()\n","true_shap_values[11] = mean_abs_shap_values[117:].sum()\n","true_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\", \"Status\", \"Weapon Used Cd\", \"Vict Descent\", \"Vict Sex\", \"Mocodes\"]\n","sorted_true_indices = np.argsort(-true_shap_values)\n","sorted_true_shap_values = true_shap_values[sorted_true_indices]\n","sorted_true_feature_names = np.array(true_feature_names)[sorted_true_indices]\n","\n","most_important_true_feature = sorted_true_feature_names[0]\n","most_important_true_value = sorted_true_shap_values[0]\n","\n","for feature, importance in zip(sorted_true_feature_names, sorted_true_shap_values):\n","    print(f\"Feature: {feature}, Summed Mean Absolute SHAP Value: {importance:.4f}\")"],"metadata":{"id":"Nkq44oaG1n9G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cTYN-Lumlx8"},"source":["# Feature Importance over Time"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"CtwZjRZemN3X","executionInfo":{"status":"ok","timestamp":1733603817514,"user_tz":360,"elapsed":311,"user":{"displayName":"Shrusti Jain","userId":"01216058439486926825"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d33a9ac8-715c-46f2-eeef-f866b4b88b87"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-30-3ec26c83526f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  time_sensitive_model.load_state_dict(torch.load('/content/basic_nn_model_time_sensitive.pkl', map_location=device))\n"]},{"output_type":"execute_result","data":{"text/plain":["BasicNN(\n","  (layers): Sequential(\n","    (0): Linear(in_features=297, out_features=256, bias=True)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=256, out_features=180, bias=True)\n","    (4): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): Dropout(p=0.2, inplace=False)\n","    (7): Linear(in_features=180, out_features=120, bias=True)\n","    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU()\n","    (10): Linear(in_features=120, out_features=80, bias=True)\n","    (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU()\n","    (13): Linear(in_features=80, out_features=69, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":30}],"source":["time_sensitive_model = BasicNN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size, dropout_rate=dropout_rate)\n","# Load pre-trained weights into the model\n","time_sensitive_model.load_state_dict(torch.load('/content/basic_nn_model_time_sensitive.pkl', map_location=device))\n","time_sensitive_model.to(device)\n","time_sensitive_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gu9YFAIOnQln","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c1b7be0-8663-4a76-f45e-a4fb38c6aa7d"},"outputs":[{"output_type":"stream","name":"stderr","text":["PermutationExplainer explainer: 4097it [07:05,  9.46it/s]\n"]}],"source":["def time_sensitive_model_predict(X):\n","    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n","    time_sensitive_model.eval()\n","    with torch.no_grad():\n","        outputs = time_sensitive_model(X_tensor)\n","        return torch.softmax(outputs, dim=1).cpu().numpy()  # Return probabilities\n","\n","# Select a single batch of data from the training set for SHAP analysis\n","batch_data, _ = next(iter(train_loader))\n","batch_data = batch_data.cpu().numpy()\n","\n","explainer = shap.Explainer(time_sensitive_model_predict, batch_data)\n","\n","# Compute SHAP values for the batch\n","shap_values = explainer(batch_data)"]},{"cell_type":"code","source":["average_shap_values = np.mean(shap_values.values, axis=0)  # Shape: (297, 69)\n","for target_class in range(69):\n","    class_shap_values = average_shap_values[:, target_class]  # Shape: (297,)\n","\n","    sorted_indices = np.argsort(-np.abs(class_shap_values))  # Sort by absolute importance\n","    sorted_shap_values = class_shap_values[sorted_indices]\n","    sorted_feature_names = np.array(ungrouped_feature_names)[sorted_indices]\n","\n","    # Plot the averaged SHAP values for this class\n","    plt.figure(figsize=(10, 6))\n","    plt.barh(sorted_feature_names[:20], sorted_shap_values[:20])  # Top 20 features\n","    plt.xlabel(\"Average SHAP Value\")\n","    plt.ylabel(\"Feature\")\n","    plt.title(f\"Averaged Feature Importance for Class {target_class}\")\n","    plt.gca().invert_yaxis()  # Invert y-axis for better readability\n","    plt.tight_layout()\n","    plt.savefig(f\"averaged_summary_plot_class_{target_class}.png\")\n","    plt.close()"],"metadata":{"id":"slEdfone1rLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true_shap_values = np.empty(12)\n","true_shap_values[:7] = mean_abs_shap_values[:7]\n","true_shap_values[7] = mean_abs_shap_values[7:12].sum()\n","true_shap_values[8] = mean_abs_shap_values[13:91].sum()\n","true_shap_values[9] = mean_abs_shap_values[92:111].sum()\n","true_shap_values[10] = mean_abs_shap_values[112:116].sum()\n","true_shap_values[11] = mean_abs_shap_values[117:].sum()\n","true_feature_names = [\"Date Occ\", \"Vict Age Was 0\", \"Vict Age\", \"Rpt Dist No\", \"Area\", \"Time Occurred\", \"Premise Code\", \"Status\", \"Weapon Used Cd\", \"Vict Descent\", \"Vict Sex\", \"Mocodes\"]\n","sorted_true_indices = np.argsort(-true_shap_values)\n","sorted_true_shap_values = true_shap_values[sorted_true_indices]\n","sorted_true_feature_names = np.array(true_feature_names)[sorted_true_indices]\n","\n","most_important_true_feature = sorted_true_feature_names[0]\n","most_important_true_value = sorted_true_shap_values[0]\n","\n","for feature, importance in zip(sorted_true_feature_names, sorted_true_shap_values):\n","    print(f\"Feature: {feature}, Summed Mean Absolute SHAP Value: {importance:.4f}\")"],"metadata":{"id":"Sg1-7fL81tmJ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["oIzSxXnoLlLO","SFNyyPVIz-qP"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}